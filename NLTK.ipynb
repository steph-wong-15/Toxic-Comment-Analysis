{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>NOTE</h3>\n",
    "    <p>Before you submit this assignment, <strong>make sure everything runs as expected</strong>:</p>\n",
    "    <ol>\n",
    "        <li><strong>restart the kernel</strong> (in the menubar, select <strong>Kernel → Restart</strong>)\n",
    "        <li><strong>run all cells</strong> (in the menubar, select <strong>Cell → Run All</strong>)</li>\n",
    "    </ol>\n",
    "    <p>Make sure to complete every cell that states \"<strong><TT>YOUR CODE IN THIS CELL</TT></strong>\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h2>CHANGELOG</h2>\n",
    "    <h3>A3-V4.ipynb</h3>\n",
    "    <p>Nov 24, 2021</br>\n",
    "    The following revisions have been added to <strong>A3-V3.ipynb</strong>.</p>\n",
    "    <ul>\n",
    "        <li>added code cell to <em>Evaluation</em> & <em>Discussion</em> sections of the <strong>Project Report</strong> for demonstrating visualization capabilities</li>\n",
    "        <li>added additional comment steps to <strong>Language Model</strong> task</li>\n",
    "        <li>updated marks for <strong>Language Model</strong> task</li>\n",
    "        <li>added <strong>PRO TIPS</strong> throughout document</li>\n",
    "        <li>updated pseudocode for <strong>Extract Features From Dataset</strong></li>\n",
    "        <li>added comments to <strong>Decision Tree</strong> task</li>\n",
    "        <li>added explanation (from <strong>Discord</strong>) of <strong>Extract Features From Dataset</strong> task</li>\n",
    "        <li>added regression and classification implementations to each model</li>\n",
    "        <li>added <strong>Plotting & Visualizations</strong> subsection</li>\n",
    "        <li>added explanation (from <strong>Discord</strong>) of <strong>What You Are Being Asked To Do</strong> subsection</li>\n",
    "        <!-- <li></li> -->\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>A3-V3.ipynb</h3>\n",
    "    <p>Nov 19, 2021</br>\n",
    "    The following revisions have been added to <strong>A3-V2.ipynb</strong>.</p>\n",
    "    <p>Extract Features From Dataset:\n",
    "    <ul>\n",
    "        <li>updated description of <strong>Extract Features From Dataset</strong></li>\n",
    "        <li>updated how many marks <strong>Extract Features From Dataset</strong> is out of</li>\n",
    "        <li>provided a breakdown of the marks in <strong>Extract Features From Dataset</strong></li>\n",
    "        <li>added code examples to <strong>Extract Features From Dataset</strong></li>\n",
    "    </ul>\n",
    "    <p>Miscellaneous:\n",
    "    <ul>\n",
    "        <li>marking rubric updated for some <strong>Tasks</strong> (but not yet finalized)</li>\n",
    "        <li>added comments for all EXAMPLE CODE to be commented out</li>\n",
    "        <li>added comments for removing <tt>raise NotImplementedError()</tt> once the code cell has begun being implemented</li>\n",
    "        <li>new <strong>TODOs</strong> added (these are for the instructor to complete)</li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>A3-V2.ipynb</h3>\n",
    "    <p>Nov 18, 2021</br>\n",
    "    The following revisions have been added to <strong>A3-V1.ipynb</strong>:</p>\n",
    "    <ul>\n",
    "        <li>added <strong>Changelog</strong></li>\n",
    "        <li>added code and a description to the <strong>Decision Tree</strong></li>\n",
    "    <li>added code to the <strong>Voting Ensemble</strong></li>\n",
    "        <li>added code for <strong>SVM Classifier</strong></li>\n",
    "        <li>added code for <strong>Decision Tree Classifier</strong></li>\n",
    "        <li>added to the <strong>Overview</strong> section to compare the task to other tasks</li>\n",
    "        <li>updated code description for <strong>n-gram Language Model</strong></li>\n",
    "        <li>added new dataset from just announced <strong>Kaggle</strong> competition on identifying toxic comments  <strong>→</strong>  <strong>$50,000</strong></li>\n",
    "        <li>transitioned to new evaluation metric taken from the just announced <strong>Kaggle</strong> competition on identifying toxic comments</li>\n",
    "        <li>changed font to light gray color for the <strong>Toxic Comments Dataset (OLD COMPETITION)</strong> since this dataset isn't the one provided by the new competition</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4><strong>TODO</strong></h4>\n",
    "    <p>The following items need to be included by the instructor in this assignment:</p>\n",
    "    <ul>\n",
    "        <li>marking rubric not finalized</li>\n",
    "        <li>need to add code to <strong>Neural Network</strong></li>\n",
    "        <li>the evaluation description for the original <strong>Idenifying Toxic Comments</strong> competition needs to be updated to use the evaluation from the new <strong>Idenifying Toxic Comments</strong> competition</li>\n",
    "        <li>code needs to be provided in the <strong>Evaluation</strong> from the new <strong>Idenifying Toxic Comments</strong> competition</li>\n",
    "        <li>add example code to <strong>Plotting & Visualizations</strong> subsection</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Assignment #3: Version 3\n",
    "### CMPT-310: Fall 2021\n",
    "\n",
    "\n",
    "**NOTE:** Complete **Quiz #4** prior to beginning this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* access a *real-world* dataset (e.g., used in **kaggle.com** competitions, etc.) rather than a *toy* dataset\n",
    "* implement a variety of machine learning models\n",
    "* download and apply *pre-trained machine learning models*\n",
    "* develop and evaluate ensembles of models\n",
    "* evaluate different machine learning models on *complex* real-world tasks\n",
    "* work with a variety of industry-standard machine learning libraries (*Tensorflow*, *PyTorch*, *sklearn*, *NLTK*, etc.)\n",
    "* visually communicate data and experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Write your **code** in the *code cells* located directly below each red *Write Code* block.\\\n",
    "Write your **text** in the *Markdown cells* that follow every **Task** description below. Also complete this Notebook's **Final Report** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    <p>The best approach to this assignment is to work on <strong>one task at a time</strong>. Treat each task as a step toward a destination.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "------\n",
    "## Preliminaries & Dependencies\n",
    "\n",
    "You will require the following **Python** packages to complete this assignment (it is likely many of these libraries are already installed via **Anaconda**, **Quiz #4**, etc.):\n",
    "* matplotlib\n",
    "* numpy\n",
    "* sklearn\n",
    "* tensorflow\n",
    "* tensorflow-datasets\n",
    "* seaborn\n",
    "* nltk\n",
    "\n",
    "\n",
    "### Imports\n",
    "\n",
    "Import the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import IPython.display as display\n",
    "import seaborn\n",
    "import sklearn\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Cross Validation Of A Dataset\n",
    "\n",
    "The following example code demonstrates using the builtin cross validation module from the [**Scikit-Learn** library](https://scikit-learn.org/stable/modules/cross_validation.html).\\\n",
    "You will likely use a variation of the following code for all of the models you will be evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "# Code from:  https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "# X = inputs or features of the data\n",
    "# y = output values from the data that we are trying to predict\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "X.shape, y.shape # shape displays the dimensions of the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "(30, 4) (30,)\n",
      "The performance of one run of the SVM model: 1.0\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "# Train the model using 80% of the dataset then test (evaluate) the model on the other 20% of the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# shape displays the dimensions of the matrices\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"The performance of one run of the SVM model:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the 5 runs of the SVM model: [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.98 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Scores for the 5 runs of the SVM model:\", scores)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Task: New Toxic Comments Dataset   (5 Marks)\n",
    "\n",
    "See https://www.kaggle.com/c/jigsaw-toxic-severity-rating.\n",
    "\n",
    "From [**Kaggle**](https://www.kaggle.com/c/jigsaw-toxic-severity-rating/data):\n",
    "> In this competition you will be ranking comments in order of severity of toxicity. You are given a list of comments, and each comment should be scored according to their relative toxicity. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity.\n",
    "> \n",
    "> **Disclaimer:** The dataset for this competition contains text that may be considered *profane, vulgar, or offensive*.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Data Description\n",
    "\n",
    "\"*Your task is to predict a score that represents the relative toxic severity of the comment. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity; scores are relative, and not constrained to a certain range of values.*\"\n",
    "\n",
    "> Note, there is no training data for this competition. You can refer to previous Jigsaw competitions for data that might be useful to train models. But note that the task of previous competitions has been to predict the probability that a comment was toxic, rather than the degree or severity of a comment's toxicity.\n",
    "> \n",
    "> **Toxic Comment Classification Challenge**\\\n",
    "> **Jigsaw Unintended Bias in Toxicity Classification**\\\n",
    "> **Jigsaw Multilingual Toxic Comment Classification**\n",
    "> \n",
    "> While we don't include training data, we do provide a set of paired toxicity rankings that can be used to validate models.\n",
    "> \n",
    "> #### Files\n",
    "> \n",
    "> **comments_to_score.csv** - for each comment text in this file, your task is to predict a score that represents the relative toxic severity of the comment. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity; scores are relative, and not constrained to a certain range of values. NOTE: the rerun version of this file has ~14k comments that will be scored by your submitted model.\\\n",
    "> **sample_submission.csv** - a sample submission file in the correct format\\\n",
    "> **validation_data.csv** - pair rankings that can be used to validate models; this data includes the annotator worker id, and how that annotator ranked a given pair of comments; note, this data contains comments that are not found in comments_to_score.\n",
    "\n",
    "\n",
    "### What You Are Being Asked To Do\n",
    "\n",
    "(A version of this is posted on **Discord**)\n",
    "\n",
    "The file `validation_data.csv` has examples of comment pairs for you to test your model against (*I don't recommend reading the toxic comments though!*).\n",
    "\n",
    "![Contents of validation_data.csv file.](./images/Toxic-comment-database-examples.png)\n",
    "\n",
    "The above image shows the first few rows of the `validation_data.csv` file. Each row contains a pair of comments. The column on the right contains comments that are more toxic than the comments in the left column. The comment pairs in the `validation_data.csv` file was ranked by human annotators.\n",
    "\n",
    "Our job is to provide every comment with a **toxicity score**. To check how accurate our scoring was, two random comments are selected and we compare which comment was identifed to be more toxic.\n",
    "\n",
    "An example of what you are being asked to do:\n",
    "* give your model the comment `This article sucks woo woo wooooooo`, which the model assigns the comment a **toxicity score** (say a score of 20)\n",
    "* give your model another comment  such as `WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!!!!!!!!???????????????????????????????????????????????...`, which the model assigns the comment a **toxicity score** (say a score of 50)\n",
    "* continue scoring *all* of the comments in `comments_to_score.csv`\n",
    "* in the competition, **Kaggle** will take the scores and compare them to two of the comments that humans determined which was more toxic\n",
    "* if your scoring matches the human rankings (i.e., the \"*more toxic*\" comment gets a higher score than the \"*less toxic*\" comment) then the model got that comparison correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=lightgray>\n",
    "    \n",
    "## Task: Toxic Comments Dataset   (OLD COMPETITION)\n",
    "\n",
    "**Kaggle** has a competition identifying *toxic comments*.\\\n",
    "See https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge.\n",
    "\n",
    "From **Kaggle**'s website:\n",
    "> ...tools to help improve online conversation. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion). So far they’ve built a range of publicly available models served through the Perspective API, including toxicity. But the current models still make errors, and they don’t allow users to select which types of toxicity they’re interested in finding (e.g. some platforms may be fine with profanity, but not with other types of toxic content).\n",
    "> \n",
    "> In this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n",
    "> \n",
    "> **Disclaimer:** the dataset for this competition contains text that may be considered *profane*, *vulgar*, or *offensive*.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "From **Kaggle**:\n",
    "> You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n",
    "> * toxic\n",
    "> * severe_toxic\n",
    "> * obscene\n",
    "> * threat\n",
    "> * insult\n",
    "> * identity_hate\n",
    ">\n",
    "> You must create a model which predicts a probability of each type of toxicity for each comment.\n",
    "> \n",
    "> File Descriptions:\n",
    "> * **train.csv** - the training set, contains comments with their binary labels\n",
    "> * **test.csv** - the test set, you must predict the toxicity probabilities for these comments. To deter hand labeling, the test set contains some comments which are not included in scoring.\n",
    "> * **sample_submission.csv** - a sample submission file in the correct format\n",
    "> * **test_labels.csv** - labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)\n",
    "\n",
    "Our **goal** is to predict for each comment the *probability* of each type of toxicity.\n",
    "This is a multi-class classification task (i.e., *more than two categories, more than two labels, more than two classes*, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download The Datasets\n",
    "\n",
    "Download the datasets from **Kaggle** (under the **Data** tab):\\\n",
    "[old dataset - \"Toxic Comment Classification Challenge\"](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)\\\n",
    "[new dataset - \"Jigsaw Rate Severity of Toxic Comments\"](https://www.kaggle.com/c/jigsaw-toxic-severity-rating/data)\n",
    "\n",
    "Or download the dataset from **Canvas** under **Files** > **Data**:\\\n",
    "[Kaggle-Toxic-Comments-Dataset (OLD)](https://canvas.sfu.ca/files/17538324/download?download_frd=1)\\\n",
    "[Kaggle-Toxic-Comments-Dataset (NEW)](https://canvas.sfu.ca/files/17622704/download?download_frd=1) is the dataset we will be using to evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    <p>Extract at least one or two features before implementing any of the models.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task: Extract Features From Dataset   (40 Marks)\n",
    "\n",
    "Use **NLTK** to extract **features** from the **Toxic Comments** dataset.\\\n",
    "The **features** will be used to train various Machine Learning models to identify toxic comments.\n",
    "\n",
    "Possible **features** to extract:\n",
    "* check if a word is in a list of swear words, or a list of words that are hate speech\n",
    "* check if punctuation is used in the *body* of a word rather than at the end of the sentence\n",
    "* check if words such as `a$$` are used where letters are replaced by visually similar symbols\n",
    "* sentence length i.e., how many words a sentence has\n",
    "* average word length in a sentence\n",
    "* unusually high number of exclamation marks, which could represent the author being frustrated or angry\n",
    "* etc.\n",
    "\n",
    "\n",
    "### Transforming Data Into Features\n",
    "\n",
    "We represent the data as matrices/vectors. So we are transforming the dataset into a matrix representation. None of the models accept text input! Example:\\\n",
    "`X = [[0, 0], [1, 3], [2, 0], [3, 1]]`\\\n",
    "`Y = [0, 1, 2, 3]`\n",
    "\n",
    "`X` is a features matrix.\n",
    "`Y` is a matrix of the target classes/output the model is trying to predict. In this case we have four classes `[0, 1, 2, 3]`. The actual classes could be non-toxic, toxic, very toxic, and extremely toxic, but we have to replace them by a number.\n",
    "\n",
    "In `X` we have four samples/datapoints/examples, the first being `[0, 0]`. Each column in the sample corresponds to a feature.\\\n",
    "For example, the first column could be number of swear words in comment and the 2nd column could be percentage of capitalized letters in a comment. In matrix entry form:\\\n",
    "`[number of swear words in comment, percentage of capitalized letters in a comment]`\\\n",
    "Thus `[0, 0]` would correspond to a comment with zero swear words and zero capitalized letters.\n",
    "\n",
    "\n",
    "### Rubric\n",
    "\n",
    "We will be evaluating this section in part by how clever your choice of features were (and that you were able to extract them).\n",
    "Simple sets of features may not be as informative as complex setds of features, but simple features are easier to extract from a dataset compared to complex features.\n",
    "\n",
    "A breakdown of the marking for this task:\n",
    "* [**10 marks**] basic features gathered (trivial)\n",
    "* [**25 marks**] quality features gathered (advanced), corresponding to unusual features or clever features most would not have considered\n",
    "* [**5 marks**] formatting the features and output correctly so it can be used immediately downstream for the machine learning classifiers without any further preprocessing needing to be done at that stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'hat' in the wordlist? True\n",
      "Is 'Hat' in the wordlist? False\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: check if a word is in a list of words\n",
    "list_of_words = [\"house\", \"hat\", \"war\"]\n",
    "word = \"hat\"\n",
    "print(\"Is 'hat' in the wordlist?\", word in list_of_words)\n",
    "\n",
    "word = \"Hat\"\n",
    "print(\"Is 'Hat' in the wordlist?\", word in list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is '?' in the characterlist? True\n",
      "Is '\\n' (newline) in the characterlist? True\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: check if a character is in a list of characters\n",
    "character_string = '?.\",!@$%^&*()\\n' # using a String as if it were a list\n",
    "character = \"?\"\n",
    "print(\"Is '?' in the characterlist?\", character in character_string)\n",
    "\n",
    "character = \"\\n\"\n",
    "print(\"Is '\\\\n' (newline) in the characterlist?\", character in character_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: for more code fragments that may be useful\n",
    "#               check the Discord server (I will not be adding new snippets to this Task here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that extracts features from the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "\n",
    "# read dataset from file\n",
    "\n",
    "# validation data\n",
    "valid_data = pd.read_csv('validation_data.csv')\n",
    "# old training data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "# comments to score\n",
    "comments = pd.read_csv('comments_to_score.csv')\n",
    "\n",
    "# iterate over each data sample in the dataset\n",
    "# extract features from each data sample\n",
    "\n",
    "# checks if there are swear words in a comment\n",
    "#for swear in swear_words:\n",
    "    #swear_comments = comments.loc[comments['text'].str.contains(swear, case=True)] \n",
    "    #swear_comments = comments.loc[comments['text'].str.count(swear) > 0]\n",
    "\n",
    "swear_words = ['fuck', 'damn', 'shit', 'bitch','ass', 'cock','cunt', 'faggot', 'FUCK', 'DAMN', 'SHIT', 'BITCH', 'ASS'\n",
    "              'COCK', 'CUNT', 'FAGGOT']\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    comments[swear] = comments.text.str.count(swear)\n",
    "\n",
    "# prepare the features in the correct format\n",
    "\n",
    "# sums the total number of swear words\n",
    "comments['total']= comments.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "# check if ! is included\n",
    "comments['exclaim'] = comments.text.str.count('!')\n",
    "\n",
    "# scale the features and outputs in the range [0-1]\n",
    "# do if necessary\n",
    "\n",
    "# prepare output values in the correct format\n",
    "\n",
    "X_comments = comments[['total','exclaim']].values.tolist()\n",
    "\n",
    "### calculate features and toxicity score from old dataset ###\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    train_data[swear] = train_data.comment_text.str.count(swear)\n",
    "\n",
    "# sums the total number of swear words\n",
    "train_data['total']= train_data.iloc[:, 8:].sum(axis=1)\n",
    "\n",
    "# check if ! is included\n",
    "train_data['exclaim'] = train_data.comment_text.str.count('!')\n",
    "\n",
    "# prepare the features in the correct format\n",
    "\n",
    "train_list = train_data[['total','exclaim']].values.tolist()\n",
    "\n",
    "# multiply columns by weights\n",
    "train_data['toxic'] = train_data['toxic']*1\n",
    "train_data['severe_toxic'] = train_data['severe_toxic']*10\n",
    "train_data['obscene'] = train_data['obscene']*5\n",
    "train_data['threat'] = train_data['threat']*20\n",
    "train_data['insult'] = train_data['insult']*5\n",
    "train_data['identity_hate'] = train_data['identity_hate']*10\n",
    "\n",
    "# sum to get toxicity score\n",
    "train_data['tox_score'] = train_data['toxic']+train_data['severe_toxic']+train_data['obscene']+train_data['threat']+train_data['insult']+train_data['identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    Classifiers take two arrays as input: <strong>array X</strong> and <strong>array y</strong>.</br>\n",
    "    <strong>array X</strong> has shape <tt>(number_of_samples, number_of_features)</tt> containing the training samples feature data</br>\n",
    "    <strong>array y</strong> of class labels/outputs (strings or integers) has shape <tt>(number_of_samples)</tt></p>\n",
    "    <p></p>\n",
    "    <p style=\"text-indent:0px\"><tt>print(photos.shape, labels.shape)</br>\n",
    "    num_samples = labels.shape[0]<br>\n",
    "    x = np.reshape(photos, (num_samples, -1))<tt></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Decision Tree   (5 Marks)\n",
    "\n",
    "Build a *decision tree* model to identify toxic comments.\n",
    "\n",
    "From Norvig & Russel's \"*AI: A Modern Approach*\" (pg. 707, 3rd ed.):\n",
    "> In many areas of industry and commerce, decision trees are usually the first method tried when a classification method is to be extracted from a data set. One important property of decision trees is that it is possible for a human to understand the reason for the output of the learning algorithm. (Indeed, this is a legal requirement for financial decisions that are subject to anti-discrimination laws.) This is a property not shared by some other representations, such as neural networks.\n",
    "\n",
    "From https://scikit-learn.org/stable/modules/tree.html:\n",
    "> `DecisionTreeClassifier` is capable of both:\n",
    "> * **binary classification** where the labels are `[-1, 1]`\n",
    "> * **multiclass classification** where the labels are `[0, ..., K-1]`\n",
    "\n",
    "\n",
    "### Type Of Task We Are Working With\n",
    "\n",
    "Note our task isn't a **classification** task (i.e., predicting a *discrete* value) but a **regression** task (i.e., predicting a *continuous* value). We could pursue one of two approaches:\n",
    "* keep the task as a regression task and use regression versions for each model (e.g., *decision tree regression*, *SVM for regression*, *neural network for regression*, etc.)\n",
    "* convert the regression task into a classification task where we are predicting a range of values rather than a specific value (i.e., discretizing the output space)\n",
    "\n",
    "To discretize the output we are predicting (i.e., convert a continuous value into a set of points/classes/categories), instead of predicting the temperature from 0 degrees Fahrenheit to 100 degrees Fahrenheit, we predict a temperature range:\n",
    "* **freezing** (0 degrees to 20 degrees Fahrenheit)\n",
    "* **cold** (20 degrees to 40 degrees Fahrenheit)\n",
    "* **moderate** (40 degrees to 60 degrees Fahrenheit)\n",
    "* **warm** (60 degrees to 80 degrees Fahrenheit)\n",
    "* **hot** (80 degrees to 100 degrees Fahrenheit)\n",
    "\n",
    "which transforms the regression problem into a 5-class classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees For Classification\n",
    "\n",
    "Example code for a **Decision Tree** performing classification. The **Decision Tree** model is predicting one category from a set of categories, such as which genre a film belongs to (`Horror`, `Comedy`, `Action`, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text visualization of decision tree:\n",
      " |--- Salary Feature <= 0.00\n",
      "|   |--- class: 0\n",
      "|--- Salary Feature >  0.00\n",
      "|   |--- Height Feature <= 5.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- Height Feature >  5.50\n",
      "|   |   |--- class: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "from sklearn import tree\n",
    "\n",
    "X = [[0, 0, -1], [1, 1, 1], [1, 10, 9], [-3, 0, 33]]\n",
    "Y = [0, 1, 4, 1]\n",
    "\n",
    "# DecisionTreeClassifier takes as input two arrays: X & Y\n",
    "#    an array X, sparse or dense, of shape (number_of_samples, number_of_features) holding the training samples\n",
    "#    and an array Y of integer values, of shape (number_of_samples) holding the class labels for the training samples\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# train the decision tree classifier model\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "# after being fitted, predict from a new set of samples\n",
    "clf.predict([[2., 2., 10.]])\n",
    "\n",
    "\n",
    "# plot a visualization of the decision tree\n",
    "tree.plot_tree(clf)\n",
    "\n",
    "# a text visualization of the decision tree\n",
    "from sklearn.tree import export_text\n",
    "text_tree = export_text(clf, feature_names=[\"First Feature\", \"Height Feature\", \"Salary Feature\"])\n",
    "print(\"Text visualization of decision tree:\\n\", text_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees For Regression\n",
    "\n",
    "Regression using **Decision Trees** is [found here](https://scikit-learn.org/stable/modules/tree.html#regression).\n",
    "\n",
    "Example code of a **Decision Tree** for regression (where the **Decision Tree** model is predicting a continuous value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 163.07999999999998, 'X[1] <= 1.0\\nmse = 1.0\\nsamples = 2\\nvalue = 1.5'),\n",
       " Text(83.7, 54.360000000000014, 'mse = 0.0\\nsamples = 1\\nvalue = 0.5'),\n",
       " Text(251.10000000000002, 54.360000000000014, 'mse = 0.0\\nsamples = 1\\nvalue = 2.5')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# code from https://scikit-learn.org/stable/modules/tree.html#regression\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "# train the decision tree regression model\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict from a new set of samples\n",
    "clf.predict([[1, 1]])\n",
    "\n",
    "# plot a visualization of the decision tree\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Decision Tree classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Rankings:  12998\n",
      "Total Rankings:  30108\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn import tree\n",
    "\n",
    "# read dataset from file\n",
    "\n",
    "# validation data\n",
    "valid_data = pd.read_csv('validation_data.csv')\n",
    "\n",
    "# comments to score\n",
    "comments = pd.read_csv('comments_to_score.csv')\n",
    "\n",
    "X_train = train_list\n",
    "y_train = train_data['tox_score']\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Train the model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Fit the model\n",
    "y_comments = clf.predict(X_comments)\n",
    "\n",
    "### Evaluate the model ###\n",
    "correct_rankings = 0\n",
    "\n",
    "#copy so dealing with dataframe for more toxic comment is easier\n",
    "valid_data2 = valid_data.copy()\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    valid_data[swear] = valid_data.less_toxic.str.count(swear)\n",
    "for swear in swear_words:\n",
    "    valid_data2[swear] = valid_data2.more_toxic.str.count(swear)\n",
    "\n",
    "# sums the total number of swear words\n",
    "valid_data['total'] = valid_data.iloc[:, 3:].sum(axis=1)\n",
    "valid_data2['total'] = valid_data2.iloc[:, 3:].sum(axis=1)\n",
    "\n",
    "#checks number of !\n",
    "valid_data['exclaim'] = valid_data.less_toxic.str.count('!')\n",
    "valid_data2['exclaim'] = valid_data2.more_toxic.str.count('!')\n",
    "\n",
    "# prepare the features in the correct format\n",
    "less_toxic_list = valid_data[['total', 'exclaim']].values.tolist()\n",
    "more_toxic_list = valid_data2[['total', 'exclaim']].values.tolist()\n",
    "\n",
    "# predict scores\n",
    "y_less_toxic = clf.predict(less_toxic_list)\n",
    "y_more_toxic = clf.predict(more_toxic_list)\n",
    "\n",
    "# compare\n",
    "correct_rankings = 0\n",
    "for i in range(len(y_less_toxic)):\n",
    "    if  y_more_toxic[i] > y_less_toxic[i]:\n",
    "        correct_rankings = correct_rankings + 1\n",
    "print(\"Correct Rankings: \", correct_rankings)\n",
    "print(\"Total Rankings: \", len(y_less_toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: SVM Classifier   (5 Marks)\n",
    "\n",
    "Build an [SVM classifier](https://scikit-learn.org/stable/modules/svm.html#classification) that identifies toxic comments.\\\n",
    "Use the **SVM**'s default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# from https://scikit-learn.org/stable/modules/svm.html#classification\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# the dataset  X:features, y:output values we are trying to predict\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "\n",
    "clf = svm.SVC(gamma='scale')\n",
    "\n",
    "# train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict new values\n",
    "clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM** for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8765009])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# the dataset  X:features, y:output values we are trying to predict\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1.2]\n",
    "\n",
    "clf = svm.SVR()\n",
    "\n",
    "# train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict new values\n",
    "clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements an SVM classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Rankings:  11226\n",
      "Total Rankings:  30108\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn import svm\n",
    "\n",
    "X_train = train_list[:20000]\n",
    "y_train = train_data['tox_score'][:20000]\n",
    "\n",
    "#clf = svm.SVR(gamma='scale', C=1.0, epsilon=0.2, cache_size=7000)\n",
    "clf = svm.SVR(gamma='scale')\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Fit the model\n",
    "y_comments = clf.predict(X_comments)\n",
    "\n",
    "### Evaluate the model ###\n",
    "correct_rankings = 0\n",
    "\n",
    "#copy so dealing with dataframe for more toxic comment is easier\n",
    "valid_data2 = valid_data.copy()\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    valid_data[swear] = valid_data.less_toxic.str.count(swear)\n",
    "for swear in swear_words:\n",
    "    valid_data2[swear] = valid_data2.more_toxic.str.count(swear)\n",
    "\n",
    "# sums the total number of swear words\n",
    "valid_data['total'] = valid_data.iloc[:, 3:].sum(axis=1)\n",
    "valid_data2['total'] = valid_data2.iloc[:, 3:].sum(axis=1)\n",
    "\n",
    "#checks number of !\n",
    "valid_data['exclaim'] = valid_data.less_toxic.str.count('!')\n",
    "valid_data2['exclaim'] = valid_data2.more_toxic.str.count('!')\n",
    "\n",
    "# prepare the features in the correct format\n",
    "less_toxic_list = valid_data[['total', 'exclaim']].values.tolist()\n",
    "more_toxic_list = valid_data2[['total', 'exclaim']].values.tolist()\n",
    "\n",
    "# predict scores\n",
    "y_less_toxic = clf.predict(less_toxic_list)\n",
    "y_more_toxic = clf.predict(more_toxic_list)\n",
    "\n",
    "# compare\n",
    "correct_rankings = 0\n",
    "for i in range(len(y_less_toxic)):\n",
    "    if  y_more_toxic[i] > y_less_toxic[i]:\n",
    "        correct_rankings = correct_rankings + 1\n",
    "        \n",
    "print(\"Correct Rankings: \", correct_rankings)\n",
    "print(\"Total Rankings: \", len(y_less_toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: Language Model   (20 Marks)\n",
    "\n",
    "Build a *language model* to identify toxic comments.\\\n",
    "Recall that language models can be built using n-grams.\\\n",
    "Also refer to **Chapter 3** in \"[*Speech and Language Processing*](https://web.stanford.edu/~jurafsky/slp3)\" (freely available textbook!) by Jurafsky & Martin for explanations of **N-gram Language Models**.\n",
    "\n",
    "Construct a **Tri-gram** language model with **backoff smoothing**.\\\n",
    "Refer to **Quiz #4** for insights into **n-gram** language models.\n",
    "\n",
    "A breakdown of the marking for this task:\n",
    "* [**15 marks**] trigram language model implemented\n",
    "* [**5 marks**] back-off smoothing implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to Quiz #4 for help with n-gram language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Tri-gram Language Model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Rankings:  7434\n",
      "Total Rankings:  7434\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "from nltk import bigrams\n",
    "from nltk.util import trigrams\n",
    "\n",
    "# Train the model\n",
    "\n",
    "#split into words and get rid of punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def split_up(comment):\n",
    "    return tokenizer.tokenize(comment)\n",
    "def make_trigram(comment):\n",
    "    return list(trigrams(comment))\n",
    "def make_bigram(comment):\n",
    "    return list(bigrams(comment))\n",
    "\n",
    "#split\n",
    "comments['split'] =  comments['text'].apply(split_up)\n",
    "\n",
    "# Create a Trigram language model\n",
    "trigrams = comments['split'].apply(make_trigram)\n",
    "\n",
    "# Create a Bigram language model\n",
    "bigrams =  comments['split'].apply(make_bigram)\n",
    "\n",
    "# Create a Unigram language model\n",
    "unigrams = comments['split']\n",
    "\n",
    "# make trigrams and bigrams into one list\n",
    "trigrams = trigrams.explode()\n",
    "bigrams = bigrams.explode()\n",
    "\n",
    "trigram_count = Counter(trigrams)\n",
    "bigram_count = Counter(bigrams)\n",
    "\n",
    "# loop through all trigrams and bigrams and divide the trigram count by bigram count\n",
    "for trigram, count in trigram_count.items():\n",
    "    for bigram, count in bigram_count.items():\n",
    "        if(tuple(i == j for i, j in zip(trigram, bigram))):\n",
    "            # add one for back-off smoothing\n",
    "            trigram_count[trigram] = (trigram_count[trigram]+1)/bigram_count[bigram]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "prob_toxic = []\n",
    "\n",
    "# multiply probabilities to get probability it is toxic\n",
    "probability_comment_toxic = []\n",
    "for comment in comments['text']:\n",
    "    for trigram in trigram_count.items():\n",
    "        if(trigram in comment):\n",
    "            prob_toxic.append(trigram_count[trigram])\n",
    "          \n",
    "\n",
    " # Evaluate the model\n",
    "# similiar to other evaluations\n",
    "# loop through less_toxic comments and more_comments\n",
    "# give toxicity score based on probabilities (add logs)\n",
    "# compare which is more toxic\n",
    "# predict scores\n",
    "\n",
    "# array with values of probabilities instead of 0\n",
    "y_less_toxic = [0]*7434\n",
    "y_more_toxic = [1]*7434\n",
    "\n",
    "# compare\n",
    "correct_rankings = 0\n",
    "for i in range(len(y_less_toxic)):\n",
    "    if  y_more_toxic[i] > y_less_toxic[i]:\n",
    "        correct_rankings = correct_rankings + 1\n",
    "        \n",
    "print(\"Correct Rankings: \", correct_rankings)\n",
    "print(\"Total Rankings: \", len(y_less_toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: Random Forest Model   (5 Marks)\n",
    "\n",
    "Build a *random forest model* to identify toxic comments.\n",
    "\n",
    "### Random Forest Classifier\n",
    "\n",
    "The **scikit-learn** implementation of **Random Forest** \"*combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class*\".\\\n",
    "Code examples for implementing a **Random Forest Classifier** is [here](https://scikit-learn.org/stable/modules/ensemble.html#forest).\\\n",
    "API information on **Random Forest Classifiers** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier).\n",
    "\n",
    "\n",
    "### Random Forest Regressor\n",
    "\n",
    "A **Random Forest** model for a regression task is conceptually identical to the classifier version above.\n",
    "\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Using **scikit-learn**, create a **Random Forest** model consisting of the following parameters (model parameters not specified can be left to their default values):\n",
    "* number of estimators = 100\n",
    "\n",
    "\n",
    "**Random Forest** for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "# Classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = [[0, 0], [1, 1]]\n",
    "Y = [0, 1]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.50699856]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "# Regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "regr.fit(X, y)\n",
    "\n",
    "print(regr.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Random Forest Classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Rankings:  9311\n",
      "Total Rankings:  30108\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_train = train_list\n",
    "y_train = train_data['tox_score']\n",
    "\n",
    "#clf = svm.SVR(gamma='scale', C=1.0, epsilon=0.2, cache_size=7000)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=4)\n",
    "\n",
    "# Train the model\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Fit the model\n",
    "y_comments = regr.predict(X_comments)\n",
    "\n",
    "### Evaluate the model ###\n",
    "correct_rankings = 0\n",
    "\n",
    "#copy so dealing with dataframe for more toxic comment is easier\n",
    "valid_data2 = valid_data.copy()\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    valid_data[swear] = valid_data.less_toxic.str.count(swear)\n",
    "for swear in swear_words:\n",
    "    valid_data2[swear] = valid_data2.more_toxic.str.count(swear)\n",
    "\n",
    "# sums the total number of swear words\n",
    "valid_data['total'] = valid_data.iloc[:, 3:].sum(axis=1)\n",
    "valid_data2['total'] = valid_data2.iloc[:, 3:].sum(axis=1)\n",
    "\n",
    "#checks number of !\n",
    "valid_data['exclaim'] = valid_data.less_toxic.str.count('!')\n",
    "valid_data2['exclaim'] = valid_data2.more_toxic.str.count('!')\n",
    "\n",
    "# prepare the features in the correct format\n",
    "less_toxic_list = valid_data[['total', 'exclaim']].values.tolist()\n",
    "more_toxic_list = valid_data2[['total', 'exclaim']].values.tolist()\n",
    "\n",
    "# predict scores\n",
    "y_less_toxic = regr.predict(less_toxic_list)\n",
    "y_more_toxic = regr.predict(more_toxic_list)\n",
    "\n",
    "# compare\n",
    "correct_rankings = 0\n",
    "for i in range(len(y_less_toxic)):\n",
    "    if  y_more_toxic[i] > y_less_toxic[i]:\n",
    "        correct_rankings = correct_rankings + 1\n",
    "        \n",
    "print(\"Correct Rankings: \", correct_rankings)\n",
    "print(\"Total Rankings: \", len(y_less_toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Voting Ensemble   (10 Marks)\n",
    "\n",
    "A **Voting Ensemble** classifier \"*combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels*\". \"*In his highly influential Society of Mind theory, Marvin Minsky proposes that human minds are constructed from an ensemble of agents*\" (from \"**AI: A Modern Approach**\" pg. 434, 3rd ed.).\n",
    "\n",
    "From https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier:\n",
    "> *The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.*\n",
    "\n",
    "Using **scikit-learn**, create two **Voting Ensemble Classifiers** (*hard voting* and *soft voting*) consisting of the following models:\n",
    "* SVM classifier\n",
    "* Decision Tree classifier\n",
    "* Random Forest classifier\n",
    "\n",
    "Use the default parameters for both *hard voting* and *soft voting* classifiers.\n",
    "\n",
    "Code examples for implementing a **Voting Ensemble Classifier** is [here](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier).\\\n",
    "API information on **Voting Ensemble Classifiers** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble classifier's predictions:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "\n",
      "The resulting dimensions of the Ensemble classifier: (150, 9)\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# from https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Load some example data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# The Ensemble classifier\n",
    "# 'estimator' is another name for 'model' or 'learner'\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft',\n",
    "                        weights=[2, 1, 2])\n",
    "\n",
    "# train the individual classifiers first\n",
    "clf1 = clf1.fit(X, y)\n",
    "clf2 = clf2.fit(X, y)\n",
    "clf3 = clf3.fit(X, y)\n",
    "# then train the ensemble of the trained classifiers (clf1, clf2, & clf3)\n",
    "eclf = eclf.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "print(\"Ensemble classifier's predictions:\\n\", eclf.predict(X))\n",
    "print(\"\\nThe resulting dimensions of the Ensemble classifier:\", eclf.transform(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Voting Ensemble** example for regression is [found here](https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Voting Ensemble classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Rankings:  8332\n",
      "Total Rankings:  30108\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "X_train = train_list\n",
    "y_train = train_data['tox_score']\n",
    "\n",
    "# Train the model\n",
    "reg1 = GradientBoostingRegressor(random_state=1)\n",
    "reg2 = RandomForestRegressor(random_state=1)\n",
    "reg3 = LinearRegression()\n",
    "ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "\n",
    "# Fit the model\n",
    "ereg = ereg.fit(X_train, y_train)\n",
    "y_comments = regr.predict(X_comments)\n",
    "\n",
    "### Evaluate the model ###\n",
    "correct_rankings = 0\n",
    "\n",
    "#copy so dealing with dataframe for more toxic comment is easier\n",
    "valid_data2 = valid_data.copy()\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    valid_data[swear] = valid_data.less_toxic.str.count(swear)\n",
    "for swear in swear_words:\n",
    "    valid_data2[swear] = valid_data2.more_toxic.str.count(swear)\n",
    "\n",
    "# sums the total number of swear words\n",
    "valid_data['total'] = valid_data.iloc[:, 3:].sum(axis=1)\n",
    "valid_data2['total'] = valid_data2.iloc[:, 3:].sum(axis=1)\n",
    "\n",
    "#checks number of !\n",
    "valid_data['exclaim'] = valid_data.less_toxic.str.count('!')\n",
    "valid_data2['exclaim'] = valid_data2.more_toxic.str.count('!')\n",
    "\n",
    "# prepare the features in the correct format\n",
    "less_toxic_list = valid_data[['total', 'exclaim']].values.tolist()\n",
    "more_toxic_list = valid_data2[['total', 'exclaim']].values.tolist()\n",
    "\n",
    "# predict scores\n",
    "y_less_toxic = regr.predict(less_toxic_list)\n",
    "y_more_toxic = regr.predict(more_toxic_list)\n",
    "\n",
    "# compare\n",
    "correct_rankings = 0\n",
    "for i in range(len(y_less_toxic)):\n",
    "    if  y_more_toxic[i] > y_less_toxic[i]:\n",
    "        correct_rankings = correct_rankings + 1\n",
    "        \n",
    "print(\"Correct Rankings: \", correct_rankings)\n",
    "print(\"Total Rankings: \", len(y_less_toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Task: Neural Network   (10 Marks)\n",
    "\n",
    "Build a *neural network* to identify toxic comments.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      " b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'\n",
      " b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'\n",
      " b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'\n",
      " b'As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.'\n",
      " b\"This is a film which should be seen by anybody interested in, effected by, or suffering from an eating disorder. It is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl, its causes and its symptoms. The girl is played by one of the most brilliant young actresses working in cinema today, Alison Lohman, who was later so spectacular in 'Where the Truth Lies'. I would recommend that this film be shown in all schools, as you will never see a better on this subject. Alison Lohman is absolutely outstanding, and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder. If barometers tell us the air pressure, Alison Lohman tells us the emotional pressure with the same degree of accuracy. Her emotional range is so precise, each scene could be measured microscopically for its gradations of trauma, on a scale of rising hysteria and desperation which reaches unbearable intensity. Mare Winningham is the perfect choice to play her mother, and does so with immense sympathy and a range of emotions just as finely tuned as Lohman's. Together, they make a pair of sensitive emotional oscillators vibrating in resonance with one another. This film is really an astonishing achievement, and director Katt Shea should be proud of it. The only reason for not seeing it is if you are not interested in people. But even if you like nature films best, this is after all animal behaviour at the sharp edge. Bulimia is an extreme version of how a tormented soul can destroy her own body in a frenzy of despair. And if we don't sympathise with people suffering from the depths of despair, then we are dead inside.\"\n",
      " b'Okay, you have:<br /><br />Penelope Keith as Miss Herringbone-Tweed, B.B.E. (Backbone of England.) She\\'s killed off in the first scene - that\\'s right, folks; this show has no backbone!<br /><br />Peter O\\'Toole as Ol\\' Colonel Cricket from The First War and now the emblazered Lord of the Manor.<br /><br />Joanna Lumley as the ensweatered Lady of the Manor, 20 years younger than the colonel and 20 years past her own prime but still glamourous (Brit spelling, not mine) enough to have a toy-boy on the side. It\\'s alright, they have Col. Cricket\\'s full knowledge and consent (they guy even comes \\'round for Christmas!) Still, she\\'s considerate of the colonel enough to have said toy-boy her own age (what a gal!)<br /><br />David McCallum as said toy-boy, equally as pointlessly glamourous as his squeeze. Pilcher couldn\\'t come up with any cover for him within the story, so she gave him a hush-hush job at the Circus.<br /><br />and finally:<br /><br />Susan Hampshire as Miss Polonia Teacups, Venerable Headmistress of the Venerable Girls\\' Boarding-School, serving tea in her office with a dash of deep, poignant advice for life in the outside world just before graduation. Her best bit of advice: \"I\\'ve only been to Nancherrow (the local Stately Home of England) once. I thought it was very beautiful but, somehow, not part of the real world.\" Well, we can\\'t say they didn\\'t warn us.<br /><br />Ah, Susan - time was, your character would have been running the whole show. They don\\'t write \\'em like that any more. Our loss, not yours.<br /><br />So - with a cast and setting like this, you have the re-makings of \"Brideshead Revisited,\" right?<br /><br />Wrong! They took these 1-dimensional supporting roles because they paid so well. After all, acting is one of the oldest temp-jobs there is (YOU name another!)<br /><br />First warning sign: lots and lots of backlighting. They get around it by shooting outdoors - \"hey, it\\'s just the sunlight!\"<br /><br />Second warning sign: Leading Lady cries a lot. When not crying, her eyes are moist. That\\'s the law of romance novels: Leading Lady is \"dewy-eyed.\"<br /><br />Henceforth, Leading Lady shall be known as L.L.<br /><br />Third warning sign: L.L. actually has stars in her eyes when she\\'s in love. Still, I\\'ll give Emily Mortimer an award just for having to act with that spotlight in her eyes (I wonder . did they use contacts?)<br /><br />And lastly, fourth warning sign: no on-screen female character is \"Mrs.\" She\\'s either \"Miss\" or \"Lady.\"<br /><br />When all was said and done, I still couldn\\'t tell you who was pursuing whom and why. I couldn\\'t even tell you what was said and done.<br /><br />To sum up: they all live through World War II without anything happening to them at all.<br /><br />OK, at the end, L.L. finds she\\'s lost her parents to the Japanese prison camps and baby sis comes home catatonic. Meanwhile (there\\'s always a \"meanwhile,\") some young guy L.L. had a crush on (when, I don\\'t know) comes home from some wartime tough spot and is found living on the street by Lady of the Manor (must be some street if SHE\\'s going to find him there.) Both war casualties are whisked away to recover at Nancherrow (SOMEBODY has to be \"whisked away\" SOMEWHERE in these romance stories!)<br /><br />Great drama.'\n",
      " b'The film is based on a genuine 1950s novel.<br /><br />Journalist Colin McInnes wrote a set of three \"London novels\": \"Absolute Beginners\", \"City of Spades\" and \"Mr Love and Justice\". I have read all three. The first two are excellent. The last, perhaps an experiment that did not come off. But McInnes\\'s work is highly acclaimed; and rightly so. This musical is the novelist\\'s ultimate nightmare - to see the fruits of one\\'s mind being turned into a glitzy, badly-acted, soporific one-dimensional apology of a film that says it captures the spirit of 1950s London, and does nothing of the sort.<br /><br />Thank goodness Colin McInnes wasn\\'t alive to witness it.'\n",
      " b'I really love the sexy action and sci-fi films of the sixties and its because of the actress\\'s that appeared in them. They found the sexiest women to be in these films and it didn\\'t matter if they could act (Remember \"Candy\"?). The reason I was disappointed by this film was because it wasn\\'t nostalgic enough. The story here has a European sci-fi film called \"Dragonfly\" being made and the director is fired. So the producers decide to let a young aspiring filmmaker (Jeremy Davies) to complete the picture. They\\'re is one real beautiful woman in the film who plays Dragonfly but she\\'s barely in it. Film is written and directed by Roman Coppola who uses some of his fathers exploits from his early days and puts it into the script. I wish the film could have been an homage to those early films. They could have lots of cameos by actors who appeared in them. There is one actor in this film who was popular from the sixties and its John Phillip Law (Barbarella). Gerard Depardieu, Giancarlo Giannini and Dean Stockwell appear as well. I guess I\\'m going to have to continue waiting for a director to make a good homage to the films of the sixties. If any are reading this, \"Make it as sexy as you can\"! I\\'ll be waiting!'\n",
      " b'Sure, this one isn\\'t really a blockbuster, nor does it target such a position. \"Dieter\" is the first name of a quite popular German musician, who is either loved or hated for his kind of acting and thats exactly what this movie is about. It is based on the autobiography \"Dieter Bohlen\" wrote a few years ago but isn\\'t meant to be accurate on that. The movie is filled with some sexual offensive content (at least for American standard) which is either amusing (not for the other \"actors\" of course) or dumb - it depends on your individual kind of humor or on you being a \"Bohlen\"-Fan or not. Technically speaking there isn\\'t much to criticize. Speaking of me I find this movie to be an OK-movie.'], shape=(10,), dtype=string)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_5 (KerasLayer)  (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                816       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 48,191,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.6714 - accuracy: 0.5103 - val_loss: 0.6251 - val_accuracy: 0.5116\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 41s 1s/step - loss: 0.5591 - accuracy: 0.6223 - val_loss: 0.5145 - val_accuracy: 0.7167\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 37s 1s/step - loss: 0.4247 - accuracy: 0.8038 - val_loss: 0.4122 - val_accuracy: 0.8190\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 38s 1s/step - loss: 0.3077 - accuracy: 0.8813 - val_loss: 0.3513 - val_accuracy: 0.8480\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 47s 2s/step - loss: 0.2261 - accuracy: 0.9213 - val_loss: 0.3209 - val_accuracy: 0.8580\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 42s 1s/step - loss: 0.1665 - accuracy: 0.9473 - val_loss: 0.3083 - val_accuracy: 0.8643\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 41s 1s/step - loss: 0.1225 - accuracy: 0.9660 - val_loss: 0.3060 - val_accuracy: 0.8699\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 42s 1s/step - loss: 0.0885 - accuracy: 0.9787 - val_loss: 0.3118 - val_accuracy: 0.8682\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 39s 1s/step - loss: 0.0628 - accuracy: 0.9875 - val_loss: 0.3233 - val_accuracy: 0.8684\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 38s 1s/step - loss: 0.0439 - accuracy: 0.9929 - val_loss: 0.3353 - val_accuracy: 0.8699\n",
      "49/49 - 10s - loss: 0.3553 - accuracy: 0.8558 - 10s/epoch - 209ms/step\n",
      "loss: 0.355\n",
      "accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# from   https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "########################\n",
    "### SET UP THE DATASET\n",
    "########################\n",
    "\n",
    "# Uses the IMDB Movie Reviews dataset\n",
    "# Split the training set into 60% and 40% to get\n",
    "#     15,000 training examples\n",
    "#     10,000 examples for validation\n",
    "#     25,000 testing examples\n",
    "train_data, validation_data, test_data = tfds.load( name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)\n",
    "\n",
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "\n",
    "# print first 10 examples\n",
    "print(train_examples_batch)\n",
    "# print the first 10 labels\n",
    "train_labels_batch\n",
    "\n",
    "\n",
    "####################################\n",
    "### SET UP THE NEURAL NETWORK MODEL\n",
    "####################################\n",
    "\n",
    "# create a Keras layer that uses a TensorFlow Hub model to embed the sentences\n",
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])\n",
    "\n",
    "# build the full model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# configure the model to use an optimizer and a loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "####################################\n",
    "### TRAIN THE NEURAL NETWORK MODEL\n",
    "####################################\n",
    "\n",
    "# Train the model for 10 epochs in mini-batches of 512 samples\n",
    "# This is 10 iterations (epochs) over all samples in the x_train and y_train tensors\n",
    "# While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set\n",
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_data.batch(512),\n",
    "                    verbose=1)\n",
    "\n",
    "\n",
    "######################################\n",
    "### EVALUATE THE NEURAL NETWORK MODEL\n",
    "######################################\n",
    "\n",
    "# Evaluate the model\n",
    "# Two values will be returned:\n",
    "#    Loss (a number which represents our error, lower values are better)\n",
    "#    Accuracy\n",
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Neural Network.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4987/4987 [==============================] - 14s 3ms/step - loss: 23.8613\n",
      "Epoch 2/10\n",
      "4987/4987 [==============================] - 16s 3ms/step - loss: 21.4249\n",
      "Epoch 3/10\n",
      "4987/4987 [==============================] - 14s 3ms/step - loss: 23.9908\n",
      "Epoch 4/10\n",
      "4987/4987 [==============================] - 12s 2ms/step - loss: 28.5464\n",
      "Epoch 5/10\n",
      "4987/4987 [==============================] - 14s 3ms/step - loss: 14.9689\n",
      "Epoch 6/10\n",
      "4987/4987 [==============================] - 12s 2ms/step - loss: 20.7097\n",
      "Epoch 7/10\n",
      "4987/4987 [==============================] - 12s 2ms/step - loss: 20.7258\n",
      "Epoch 8/10\n",
      "4987/4987 [==============================] - 16s 3ms/step - loss: 15.1548\n",
      "Epoch 9/10\n",
      "4987/4987 [==============================] - 12s 2ms/step - loss: 21.2366\n",
      "Epoch 10/10\n",
      "4987/4987 [==============================] - 11s 2ms/step - loss: 14.6088\n",
      "Correct Rankings:  9311\n",
      "Total Rankings:  30108\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "X_train = np.array(train_list)\n",
    "y_train = np.array(train_data['tox_score'])\n",
    "\n",
    "# train the model\n",
    "comments_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "comments_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())\n",
    "\n",
    "# fit the model \n",
    "comments_model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "y_comments = comments_model.predict(X_comments)\n",
    "    \n",
    "### Evaluate the model ###\n",
    "correct_rankings = 0\n",
    "\n",
    "#copy so dealing with dataframe for more toxic comment is easier\n",
    "valid_data2 = valid_data.copy()\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    valid_data[swear] = valid_data.less_toxic.str.count(swear)\n",
    "for swear in swear_words:\n",
    "    valid_data2[swear] = valid_data2.more_toxic.str.count(swear)\n",
    "\n",
    "# sums the total number of swear words\n",
    "valid_data['total'] = valid_data.iloc[:, 3:].sum(axis=1)\n",
    "valid_data2['total'] = valid_data2.iloc[:, 3:].sum(axis=1)\n",
    "\n",
    "#checks number of !\n",
    "valid_data['exclaim'] = valid_data.less_toxic.str.count('!')\n",
    "valid_data2['exclaim'] = valid_data2.more_toxic.str.count('!')\n",
    "\n",
    "# prepare the features in the correct format\n",
    "less_toxic_list = valid_data[['total', 'exclaim']].values.tolist()\n",
    "more_toxic_list = valid_data2[['total', 'exclaim']].values.tolist()\n",
    "\n",
    "# predict scores\n",
    "y_less_toxic = regr.predict(less_toxic_list)\n",
    "y_more_toxic = regr.predict(more_toxic_list)\n",
    "\n",
    "# compare\n",
    "correct_rankings = 0\n",
    "for i in range(len(y_less_toxic)):\n",
    "    if  y_more_toxic[i] > y_less_toxic[i]:\n",
    "        correct_rankings = correct_rankings + 1\n",
    "        \n",
    "print(\"Correct Rankings: \", correct_rankings)\n",
    "print(\"Total Rankings: \", len(y_less_toxic))\n",
    "\n",
    "# Train the model\n",
    "# create a Keras layer that uses a TensorFlow Hub model to embed the sentences\n",
    "#embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "#hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "#hub_layer(comments['text'][:3])\n",
    "#print(comments['text'][:3])\n",
    "\n",
    "# build the full model\n",
    "#model = tf.keras.Sequential()\n",
    "#model.add(hub_layer)\n",
    "#model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dense(1))\n",
    "#model.summary()\n",
    "\n",
    "# configure the model to use an optimizer and a loss function\n",
    "#model.compile(optimizer='adam',\n",
    "              #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              #metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "#history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    #epochs=10,\n",
    "                    #validation_data=validation_data.batch(512),\n",
    "                    #verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "# Two values will be returned:\n",
    "#    Loss (a number which represents our error, lower values are better)\n",
    "#    Accuracy\n",
    "#results = model.evaluate(comments.batch(512), verbose=2)\n",
    "#for name, value in zip(model.metrics_names, results):\n",
    "    #print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: Naive Bayes Classifier   (5 Marks)\n",
    "\n",
    "Build a **Naive Bayes classifier** to identify toxic comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))\n",
    "\n",
    "print(clf_pf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression (Linear Model)\n",
    "\n",
    "For regression, use a **Linear Regression** model instead of *Naive Bayes*.\\\n",
    "A succinct overview of using a [linear model to detect diabetes](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) provides a good explanation of an end-to-end experimental workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [-0.9]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# train the model with data\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]],\n",
    "        [0, 1, 2])\n",
    "\n",
    "# make predictions\n",
    "prediction = reg.predict([[-0.8, -1]])\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Naive Bayes Classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Rankings:  7434\n",
      "Total Rankings:  30108\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn import linear_model\n",
    "\n",
    "X_train = train_list\n",
    "y_train = train_data['tox_score']\n",
    "# Train the model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "reg.fit(X_train, y_train)\n",
    "y_comments = reg.predict(X_comments)\n",
    "\n",
    "### Evaluate the model ###\n",
    "correct_rankings = 0\n",
    "\n",
    "#copy so dealing with dataframe for more toxic comment is easier\n",
    "valid_data2 = valid_data.copy()\n",
    "\n",
    "# checks number of swear words in a comment\n",
    "for swear in swear_words:\n",
    "    valid_data[swear] = valid_data.less_toxic.str.count(swear)\n",
    "for swear in swear_words:\n",
    "    valid_data2[swear] = valid_data2.more_toxic.str.count(swear)\n",
    "\n",
    "# sums the total number of swear words\n",
    "valid_data['total'] = valid_data.iloc[:, 3:].sum(axis=1)\n",
    "valid_data2['total'] = valid_data2.iloc[:, 3:].sum(axis=1)\n",
    "\n",
    "#checks number of !\n",
    "valid_data['exclaim'] = valid_data.less_toxic.str.count('!')\n",
    "valid_data2['exclaim'] = valid_data2.more_toxic.str.count('!')\n",
    "\n",
    "# prepare the features in the correct format\n",
    "less_toxic_list = valid_data[['total', 'exclaim']].values.tolist()\n",
    "more_toxic_list = valid_data2[['total', 'exclaim']].values.tolist()\n",
    "\n",
    "# predict scores\n",
    "y_less_toxic = regr.predict(less_toxic_list)\n",
    "y_more_toxic = regr.predict(more_toxic_list)\n",
    "\n",
    "# compare\n",
    "correct_rankings = 0\n",
    "for i in range(len(y_less_toxic)):\n",
    "    if  y_more_toxic[i] > y_less_toxic[i]:\n",
    "        correct_rankings = correct_rankings + 1\n",
    "        \n",
    "print(\"Correct Rankings: \", correct_rankings)\n",
    "print(\"Total Rankings: \", len(y_less_toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task: Evaluation   (10 Marks)\n",
    "\n",
    "The following classification models are to be evaluated (default parameters can be used in both models):\n",
    "* [Gaussian Naive Bayes classifier](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes) \n",
    "* [Decision Tree classifier](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
    "* SVM classifier\n",
    "* Tri-gram Language Model\n",
    "* Neural Network classifier\n",
    "* Random Forest classifier\n",
    "* Ensemble Model classifier\n",
    "\n",
    "Models will be *trained* on the **training data**.\\\n",
    "Models will be *evaluated* on the **test data**.\n",
    "\n",
    "<font color=red>**TBD**.<font color=black> The below is *not* the final evaluation method but the one used in the **Kaggle** competition.\n",
    "\n",
    "<font color=lightgray>\n",
    "\n",
    "The evaluation description for the original **Idenifying Toxic Comments** task needs to be updated.\n",
    "    \n",
    "> Submissions are evaluated on the **mean column-wise ROC AUC**.\\\n",
    "> In other words, the score is the **average of the individual AUCs of each predicted column**.\n",
    "> \n",
    "> **Submission File**\n",
    "> \n",
    "> For each id in the test set, you must predict a probability for each of the six possible types of comment toxicity (*toxic, severetoxic, obscene, threat, insult, identityhate*). The columns must be in the same order as shown below. The file should contain a header and have the following format:\n",
    "> \n",
    "> \t\tid,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
    "> \t\t00001cee341fdb12,0.5,0.5,0.5,0.5,0.5,0.5\n",
    "> \t\t0000247867823ef7,0.5,0.5,0.5,0.5,0.5,0.5\n",
    "> \t\t...\n",
    "> \t\tetc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "\n",
    "# keep track of how many comment pairs we correctly rank\n",
    "total_correct_comment_pair_rankings = 0\n",
    "\n",
    "# get next pair of comments from validation_data.csv\n",
    "# NOTE: comment1 is from the column corresponding to \"LESS TOXIC\"\n",
    "#       comment2 is from the column corresponding to \"MORE TOXIC\"\n",
    "comment1 = \"Comment from Wikipedia! (less toxic comment)\"\n",
    "comment2 = \"ANOTHER Comment from Wikipedia! Swear word: bA$$ (more toxic comment)\"\n",
    "\n",
    "# convert the comment's text into a feature vector e.g., [0, 0, 2.51, 1, ...]\n",
    "comment1_features = extract_features(comment1)\n",
    "comment2_features = extract_features(comment2)\n",
    "\n",
    "# compute the toxicity score of each comment\n",
    "toxicicity_score_of_comment1 = some_model.predict(comment1_features)\n",
    "toxicicity_score_of_comment2 = some_model.predict(comment2_features)\n",
    "\n",
    "if toxicicity_score_of_comment2 > toxicicity_score_of_comment1:\n",
    "    total_correct_comment_pair_rankings = total_correct_comment_pair_rankings + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code for evaluating a model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation sections was implemented at the end of each model\n",
      "Check individual models for each evaluation\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "print('Evaluation sections was implemented at the end of each model')\n",
    "print('Check individual models for each evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "# Task: Project Report   \n",
    "\n",
    "The total marks for all of the sections below is **80 Marks**.\n",
    "\n",
    "This section corresponds to the write-up of the project. Your write-up is to be included within this **Jupyter Notebook** below (the code for this assignment is in the code cells above).\\\n",
    "The **Project Report** will consist of a few sections that each discuss a different stage of the end-to-end experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview    (10 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the problem/task you are addressing\n",
    "* provide concrete examples of the problem\n",
    "* why the problem is worth the time and effort trying to solve\n",
    "* compare the task with other tasks that are similar\n",
    "\n",
    "The following are optional:\n",
    "* *Related Work* i.e., what have other people tried\n",
    "* historical background of the problem\n",
    "* discuss strategies used in other tasks that are similar to **Toxic Comment Identification**\n",
    "* discuss the differences with those tasks that are similar to **Toxic Comment Identification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset    (10 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the dataset's size\n",
    "* languages dataset contains\n",
    "* anything unusual about the data\n",
    "* how representative the dataset is of everyday communication\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Features    (10 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the features that were extracted\n",
    "* the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models    (10 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the models used\n",
    "* any specific parameters, configuration, or settings of each model\n",
    "* any differences in how each model was trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation    (10 Marks)\n",
    "\n",
    "This section discusses:\n",
    "* how you evaluated the models in order to compare their relative performance\n",
    "* evaluating models based on *overall performance*\n",
    "* evaluating models based on their performance on *individual comment types* i.e., which model was best at detecting the comment type **identityhate**?\n",
    "* use visuals, tables, charts, graphs, etc. to communicate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discussion    (30 Marks)\n",
    " \n",
    "Compare the performance of the above models on **Identifying Toxic Comments**.\\\n",
    "Use visuals, charts, graphs, etc. to communicate your results.\n",
    "\n",
    "Discuss:\n",
    "* your findings in general\n",
    "* compare the performance of the various models (was the performance what you expected?)\n",
    "* which system performed best? why?\n",
    "* which system had the worst performance? why?\n",
    "* discuss the reasons which lead to the results from the evaluation\n",
    "* provide some ideas you would like to have tried (provided you had more time or resources) that could potentially improve the performance of the models or a question that you were interested in exploring (i.e., *Future Work*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting & Visualizations\n",
    "\n",
    "Examples of various plots and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from scipy import stats\n",
    "\n",
    "correct = [12998,11226,9311,8332,9311,7434]\n",
    "models = ['Decision Trees','SVM','RF', 'Voting Emsemble', 'NN', 'Naive Bayes']\n",
    "\n",
    "plt.plot(models, correct, 'b.')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Comments Ranked Correctly')\n",
    "plt.title('Correct Comments vs Model')\n",
    "plt.show()\n",
    "\n",
    "# Load example miles per gallon dataset\n",
    "#mpg = seaborn.load_dataset(\"mpg\")\n",
    "# Plot miles per gallon against horsepower\n",
    "#seaborn.relplot(x=\"horsepower\", y=\"mpg\", hue=\"origin\", size=\"weight\", sizes=(40, 400), alpha=0.4, data=mpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h1>YOUR PROJECT REPORT BEGINS BELOW THIS CELL</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFORMATION**\\\n",
    "Student Name: Diana Stephanie Wong\\\n",
    "Student ID: 301373179\\\n",
    "Student SFU Email: dwa102@sfu.ca\n",
    "\n",
    "# Overview\n",
    "\n",
    "   The problem that we are trying to address is predicting how toxic a comment is relative to another comment. Toxic comments are define as comments that are negative, include inappropriate language, discrimination, or other types of hateful behaviour. In this analysis, we give each comment a score that represents its toxicity and the higher the value, the more toxic a comment is deemed to be. For example, if we have two comments, one being \"you are bad\" and the other being \"YOU SUCK!!! QUIT THE GAME!!\", the latter should be given a higher toxicity score. So if we were to give those comments as input to our models, the score of the first should be lower than the second and when we evaluate the model, it should show that the second comment is more toxic. \n",
    "   \n",
    "   This is a worthwhile problem because it can be applied to many online spaces such as video game lobbies, Twitter posts, and comments on videos. Since all those spaces have users that can create toxic comments, having a method for identifying more toxic comments would be beneficial and ensure that those environments feel safe to all users. Since 83% of adults have experienced negative interactions in online games, a method for finding the toxicity of comments can help developers better moderate those enviroments. There have been previous attempts to solve similiar tasks. One example is the Kaggle competition to classify toxic comments into categories such as comments that included insults, threats, and so on. While being able to determine the type of toxic behaviour is benefical, extending that into giving each comment a toxicity score can help us better compare and rank comments. Being able to see the relative severity of each comment in a numerical way can help us determine which comments are more toxic and those can result in more severe consquences for the users, while the ones who made comments with lower scores can recieve warnings or milder punishments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "There were 3 datasets that were used in this analysis. The first was called 'train.csv' and it taken from an old Kaggle competition where the goal was to classify comments into different categories such as threats, insults, etc. The dataset contains 159571 comments and they were written in English. Along with the comment text, a one (if the comment was classified as part of that category) or a zero (if it was not part of that category) were given to each of these categories: toxic, severe toxic, obscene, threat, insult, and identity hate. This data was used to train the models by giving each comment a toxicity score based on which type toxic language was present. The dataset contains 159571 comments and they were written in English. The dataset does not completely represent everyday language used in in-person interactions, but it respresents online communications fairly well. For examples, many of the comments were mundane comments and suggestions that could be observed in the comments sections of blogs and so on. There were also more toxic ones that were likely to be seen online since the web provides commenters with more anonymity so they use bolder language. \n",
    "\n",
    "The second dataset was called 'comments_to_score.csv' and it made up of comments that were given to the trained models so those comments were given toxicity scores. The dataset was made up of 7537 comments which were in English. The majority of the comments seemed to represent everyday online interactions fairly well, but some has large amounts of repeated text, formulas, and bits of other languages (non-English character).\n",
    "\n",
    "The third dataset was called 'validation_data.csv' and it contained a pair of comments, one that was deemed more toxic and one that was less toxic. The dataset contained 30108 pairs of comments (a total of 60216 comments) and they were in English. They also seemed to represent online communications fairly well and the comments that were rated more toxic appeared to have more toxic language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "During my first attempt at extracting the features I decided to create a list of swear words and then go through the dataset and count the number of swear words in each comment. At first I simply checked if there was a swear word in the comment, but later I modified the code so that it counted all the occurences. I chose this feature because the more swear words, the more toxic a comment should be rated. \n",
    "\n",
    "The second feature I extracted was the number of exclamation marks in a comment. This feature was included because usually the more exclamation marks there are in a comment, the more likely it is that the person was frustrated or angry. Due to time constraints, I started with extracting 2 features and planned on added more to optimize the models as more progress was made.\n",
    "\n",
    "All the features could be extended so they determine the ratio of swear words or negative words compared to the length of the text. By finding the ratio, we can see comments that are almost entirely made of vulgur language as opposed to those that contain more regular words. Those with a higher ratio would get higher toxic scores. To get the ratio we could need to count swear or negative words in a sentence then divide by the total number of words in that text.\n",
    "\n",
    "There are many more potential features that can be added to improve the performance of the model. Adding a feature that counts the number of negative words in a comment would likely improve the models. To get negative words, we could import a dataset containing negative words and use those to count the number of times they appear in each comment.\n",
    "\n",
    "Another feature could be counting the number of times a race, religion, ethnicity, or sexual orientation were mentioned in a comment. Idealy we could also check if those comments also contained negative speech and then assign a higher toxicity score if both are included.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Discuss:\n",
    "* the models used\n",
    "* any specific parameters, configuration, or settings of each model\n",
    "* any differences in how each model was trained\n",
    "\n",
    "### Decision Tree regression\n",
    "I chose to do use a Decision Tree Regression model because it would likely give more accurate results than a classifier. I tested the Decision Tree Classifier as well and it took a similiar amount of time so I went with the regression. This model was given the training data features as extracted previously as well as the toxicity score calculated for the training model. The default settings were kept for the model and after it was trained it was applied to the comments that needed to be scored.\n",
    "\n",
    "### SVM regression\n",
    "Similarly for the I used a regression for the SVM model. The default settings were used for this model. In addition, this took a long time to load when the full data was given so instead of training it will all the data, the training data given to this model was reduced which may make results worse. \n",
    "\n",
    "### Random Forest regression\n",
    "A regression model was used for this model. The following parameters were usef for this model: max_depth=2, random_state=0, n_estimators=4.\n",
    "\n",
    "### Tri-gram Language Model\n",
    "Due to time constrains and the fact that the loops took a long time to load, this model did not produce results. To get the probabilities of the sentences being toxic, we would have used the probabilies of the trigrams occuring as used from training and we would have added the probabilies whenever a trigram was found in the comment we were scoring.\n",
    "\n",
    "### Neural Network regression\n",
    "For this model the following was used to train the model tf.keras.Sequential([\n",
    " layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "]). Additionally 10 epochs were used for this regression model.\n",
    "\n",
    "\n",
    "### Ensemble Model regression\n",
    "For this regression model the following regression models were used:\n",
    "GradientBoostingRegressor(random_state=1), \n",
    "RandomForestRegressor(random_state=1), \n",
    "LinearRegression().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "I evaluated the models using the same process. The two comments were put into the models and given a score. If the score of the more_toxic comment was higher, I incremented the amount of correctly ranked comments by one. The number of correctly ranked comments is given in a figure below for all the models. The overall performance was mainly based on the number of correctly ranked comments, with the amount of time it took to train also being taken into consideration. The models were not evaluated based on individual comments and in future work that will be something that should be explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "After extracting all the features used, the same training data was given to all the models excluding the neural network regressor and the n-gram language model. In terms of time the SVM and the Neural Network performed poorer thant the other models because they were significantly slower. The SVM in particular took the most time and in order to have enough time to run the rest of the analysis, I decided to restrict the amount of data used to train it. I also attempted to used the classifier for SVM instead of regression, however; that did not improve the time by a noticeable amount. I did not expect the SVM to take that much longer to run so that was suprising. The decision trees, random forest, voting emsemble, and naive bayes all had reasonable running times so their performance in that respect was good. Moving on to the performance of each model in regards to how many comments they ranked correctly when they ran the validation data, the Decision Tree has the best performance with 12998 of the 30108 comments being ranked correctly. The worst peformance was by the Naive Bayes model which only ranked 7434 of the 30108 comments being ranked correctly. The results of the other models are plotted in the figure below. Most did not do very well, the only one getting close to the performance of the Decision Tree was the SVM. So for overall performance the Decision tree was the best as it ranked the most correctly and it took a reasonable amount of time to train the data. While the SVM and Neural Network took longer their performance in ranking was ok so the are not the worst overall. The worst over all was the Naive Bayes because of its very low values for correctly predicting which comment more toxic. More features would be needed to better decide which model will provide the best performance.\n",
    "\n",
    "The main reason why the number of correctly ranked comment is so low is due to the fact that in the evaluation of how many comments were ranked correctly, if the comments were given the same score, the number of correctly ranked comments would not go up. Since the features I extracted were very basic, only 2 features were used, many comments were given the same score. To test this, I tried incrementing the number of correctly ranked comments if the value of the more_toxic comment was greater than or equal to the less_toxic comment and the number of correct comments increased significantly (to about 20000 of the 30108 comments). To improve the performance of all the models, the number of features used should be increased and modified so it takes more variables into account. This should be down in future work. Along with implementing more features, in future work I would like to change more of the parameters and see how the models are effected and also provide the SVM model with the full set of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(models, correct, 'b.')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Comments Ranked Correctly')\n",
    "plt.title('Correct Comments vs Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
